package za.co.absa.spline.persistence.hdfs

import java.io.{File, FileWriter, IOException}
import java.util.Properties

import org.apache.commons.configuration.Configuration
import org.apache.hadoop.fs.FileSystem
import org.apache.hadoop.fs.permission.FsPermission
import org.apache.spark.SparkContext
import za.co.absa.spline.common.ARM.using
import za.co.absa.spline.persistence.api.{DataLineageReader, DataLineageWriter, PersistenceFactory}

class HdfsAtlasFormatPersistenceFactory(configuration: Configuration) extends PersistenceFactory(configuration: Configuration){

  private val fileNameKey = "spline.hdfs.file.name"
  private val filePermissionsKey = ""

  private val hadoopConfiguration = SparkContext.getOrCreate().hadoopConfiguration
  private val fileName = configuration getString(fileNameKey, "_LINEAGE")
  private val defaultFilePermissions = FsPermission.getFileDefault.applyUMask(FsPermission.getUMask(FileSystem.get(hadoopConfiguration).getConf))
  private val filePermissions = new FsPermission(configuration.getString(filePermissionsKey, defaultFilePermissions.toShort.toString))

  createAtlasTemporaryConfigurationFile()

  def createTempDirectory(): File = {
    val temp = File.createTempFile("temp", System.nanoTime().toString)
    if (!temp.delete) throw new IOException("Could not delete temp file: " + temp.getAbsolutePath)
    if (!temp.mkdir) throw new IOException("Could not create temp directory: " + temp.getAbsolutePath)
    temp
  }

  private def createAtlasTemporaryConfigurationFile(): Unit = {
    val atlasConfTempDir = createTempDirectory()
    val atlasConfTempFile = new File(atlasConfTempDir, "atlas-application.properties")
    atlasConfTempFile.deleteOnExit()
    atlasConfTempDir.deleteOnExit()

    System.setProperty("atlas.conf", atlasConfTempDir.getAbsolutePath)

    import scala.collection.JavaConverters._

    val atlasProps = new Properties() {
      (configuration getKeys "atlas").asScala.foreach(key =>
        setProperty(key, configuration getString key))
    }


    using (new FileWriter(atlasConfTempFile)) {
      atlasProps.store(_, "DO NOT MODIFY! The content is automatically generated by Spline.")
    }

    log info s"Atlas config file created: $atlasConfTempFile"
  }

  override def createDataLineageWriter: DataLineageWriter = new HdfsAtlasFormatDataLineageWriter(hadoopConfiguration, fileName, filePermissions)

  override def createDataLineageReader: Option[DataLineageReader] = None
}
